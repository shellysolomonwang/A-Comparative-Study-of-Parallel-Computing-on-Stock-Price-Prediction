{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27486a6d311f4cd2aa6203d819666471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1588575344103_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-88-145.ec2.internal:20888/proxy/application_1588575344103_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-89-26.ec2.internal:8042/node/containerlogs/container_1588575344103_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spark Session, Pipeline, Functions, and Metrics\n",
    "# from pyspark import SparkContext, SparkConf\n",
    "# from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import rand\n",
    "# from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# # Keras / Deep Learning\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation\n",
    "# from keras import optimizers, regularizers\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # Elephas for Deep Learning on Spark\n",
    "# from elephas.ml_model import ElephasEstimator\n",
    "\n",
    "# time \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4379350d2b054cd49d473dd3fd22251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\n",
      "Collecting python-dateutil>=2.6.1\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.0.3 python-dateutil-2.8.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas\")\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "# run locally with 4 word nodes\n",
    "# conf = SparkConf().setAppName('678 Spark Pipeline').setMaster('local[4]') \n",
    "# sc = SparkContext()\n",
    "# sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5d323ed616492da3610b0054e7b7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=yarn appName=livy-session-0>"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a72b03366bb40cd9172e537c3602cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Data to Spark Dataframe\n",
    "path = './data/simplified_train.csv'\n",
    "path = \"s3://shelly-678-project/simplified_train.csv\"\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15f3345b4174648af3a3e2bed59ceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change name for label column\n",
    "label = 'returnsOpenNextMktres10'\n",
    "df = df.withColumnRenamed(label,'label')\n",
    "\n",
    "# Shuffle Data\n",
    "df = df.orderBy(rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Step 4:</b> Create the Spark Data Pipeline\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355d430b6f3545478a635c716c0bf1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_data_pipeline():\n",
    "    # Spark Pipeline\n",
    "    label = 'returnsOpenNextMktres10'\n",
    "    cat_feature = 'assetCode'\n",
    "    num_features = ['volume',\n",
    "                     'close',\n",
    "                     'open',\n",
    "                     'returnsClosePrevRaw1',\n",
    "                     'returnsOpenPrevRaw1',\n",
    "                     'returnsClosePrevMktres1',\n",
    "                     'returnsOpenPrevMktres1',\n",
    "                     'returnsClosePrevRaw10',\n",
    "                     'returnsOpenPrevRaw10',\n",
    "                     'returnsClosePrevMktres10',\n",
    "                     'returnsOpenPrevMktres10',\n",
    "                     'urgency',\n",
    "                     'takeSequence',\n",
    "                     'marketCommentary',\n",
    "                     'companyCount',\n",
    "                     'relevance',\n",
    "                     'bodySize',\n",
    "                     'sentenceCount',\n",
    "                     'wordCount',\n",
    "                     'firstMentionSentence',\n",
    "                     'sentimentClass',\n",
    "                     'sentimentNegative',\n",
    "                     'sentimentNeutral',\n",
    "                     'sentimentPositive',\n",
    "                     'sentimentWordCount',\n",
    "                     'noveltyCount12H',\n",
    "                     'noveltyCount24H',\n",
    "                     'noveltyCount3D',\n",
    "                     'noveltyCount5D',\n",
    "                     'noveltyCount7D',\n",
    "                     'volumeCounts12H',\n",
    "                     'volumeCounts24H',\n",
    "                     'volumeCounts3D',\n",
    "                     'volumeCounts5D',\n",
    "                     'volumeCounts7D']\n",
    "    # Pipeline Stages List\n",
    "    stages = []\n",
    "    \n",
    "    # Loop for StringIndexer and OHE for Categorical Variables\n",
    "    string_indexer = StringIndexer(inputCol=cat_feature, outputCol=cat_feature + \"_index\").setHandleInvalid(\"keep\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[string_indexer.getOutputCol()],\n",
    "                                     outputCols=[cat_feature + \"_class_vec\"])\n",
    "    stages += [string_indexer, encoder]\n",
    "\n",
    "    # Scale Feature\n",
    "    unscaled_assembler = VectorAssembler(inputCols=num_features, outputCol=\"unscaled_features\")\n",
    "    scaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"scaled_features\")\n",
    "    stages += [unscaled_assembler, scaler]\n",
    "\n",
    "\n",
    "    # Assemble or Concat the Categorical Features and Numeric Features\n",
    "#     assembler_inputs = [feature + \"_class_vec\" for feature in cat_features]\n",
    "#     assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"assembled_inputs\") \n",
    "#     stages += [assembler]\n",
    "\n",
    "    # Assemble Final Training Data of Scaled, and Categorical Engineered Features\n",
    "    assembler_final = VectorAssembler(inputCols=[\"scaled_features\",cat_feature + \"_class_vec\"], outputCol=\"features\")\n",
    "    stages += [assembler_final]\n",
    "    print(\"Stages for data transformation pipeline:\\n\",stages)\n",
    "    # Set Pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Step 7:</b> Build a Generalized Linear Regression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689ca4d1389146ae93f98867d251fc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def training(df, percentage, model_name):\n",
    "    \"\"\"\n",
    "    main func of the program\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # get exact percentage of data\n",
    "    if percentage < 1:\n",
    "        df, df_rest = df.randomSplit([percentage, (1-percentage)],seed=1234)\n",
    "    print(\"Using {} % of the total dataset\".format(percentage*100))\n",
    "    # create data processing pipeline\n",
    "    pipeline = create_data_pipeline()\n",
    "    print(\"Created data processing pipeline\")\n",
    "    # Split Data into Train / Test Sets\n",
    "    train_data, test_data = df.randomSplit([.8, .2],seed=1234)\n",
    "    \n",
    "    # Fit Pipeline to Data\n",
    "    pipeline_model = pipeline.fit(train_data)\n",
    "    \n",
    "    # Transform Data using Fitted Pipeline\n",
    "    train_data = pipeline_model.transform(train_data)\n",
    "    test_data = pipeline_model.transform(test_data)\n",
    "    \n",
    "    # select final columns\n",
    "    train_data = train_data.select('features','label')\n",
    "    test_data =test_data.select('features','label')\n",
    "#     print(train_data.limit(5).toPandas())\n",
    "#     return train_data, test_data\n",
    "    if model_name == \"GLR\":\n",
    "        # builde model\n",
    "        glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)    \n",
    "        # training\n",
    "        model = glr.fit(train_data)\n",
    "\n",
    "    summary = model.summary\n",
    "\n",
    "    # make predictions\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # evaluate the result\n",
    "    evaluator1 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator1.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "    evaluator2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "    mse = evaluator2.evaluate(predictions)\n",
    "    print(\"Mean Squared Error (MSE) on test data = %g\" % mse)\n",
    "\n",
    "    # time calculation\n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "    print(\"Total processing time : \", total_time)\n",
    "    print()\n",
    "\n",
    "    return predictions, summary, (percentage, rmse, mse, total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca8b8bcf91b4f168c746fcf100a3c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20.0 % of the total dataset\n",
      "Stages for data transformation pipeline:\n",
      " [StringIndexer_9a24dc5d1433, OneHotEncoderEstimator_3d1883612403, VectorAssembler_65dcfebec77e, StandardScaler_10eef180dab3, VectorAssembler_5089d0fc16d4]\n",
      "Created data processing pipeline\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0638285\n",
      "Mean Squared Error (MSE) on test data = 0.00407408\n",
      "Total processing time :  203.51048302650452\n",
      "\n",
      "Using 40.0 % of the total dataset\n",
      "Stages for data transformation pipeline:\n",
      " [StringIndexer_fd250fa2be8a, OneHotEncoderEstimator_16abef6b60ed, VectorAssembler_951d16ede031, StandardScaler_9a9edfcd6148, VectorAssembler_cf410e3151c6]\n",
      "Created data processing pipeline\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0637236\n",
      "Mean Squared Error (MSE) on test data = 0.0040607\n",
      "Total processing time :  197.68755865097046\n",
      "\n",
      "Using 80.0 % of the total dataset\n",
      "Stages for data transformation pipeline:\n",
      " [StringIndexer_6bbfe5ed29d9, OneHotEncoderEstimator_fbeb953a1633, VectorAssembler_9605d5619625, StandardScaler_c6c0565f179a, VectorAssembler_591f5cf094b9]\n",
      "Created data processing pipeline\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0640446\n",
      "Mean Squared Error (MSE) on test data = 0.00410171\n",
      "Total processing time :  203.95586252212524\n",
      "\n",
      "Using 100.0 % of the total dataset\n",
      "Stages for data transformation pipeline:\n",
      " [StringIndexer_ed8f7a52e088, OneHotEncoderEstimator_ed723d1b04e2, VectorAssembler_a3214837ace4, StandardScaler_50d7e7dd60cc, VectorAssembler_8bf25c6b6db8]\n",
      "Created data processing pipeline\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0639769\n",
      "Mean Squared Error (MSE) on test data = 0.00409304\n",
      "Total processing time :  195.0188548564911\n",
      "\n",
      "All Done!"
     ]
    }
   ],
   "source": [
    "percentages = [.2, .4, .8, 1.0]\n",
    "predictions_list = []\n",
    "summary_list = []\n",
    "result_list = []\n",
    "for i in percentages:\n",
    "    predictions, summary, result = training(df, i,\"GLR\")\n",
    "    predictions_list.append(predictions)\n",
    "    summary_list.append(summary)\n",
    "    result_list.append(result)\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3747c7800174226a80da2c61c004aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.2, 0.06382852222837014, 0.004074080249857543, 203.51048302650452), (0.4, 0.06372361725251827, 0.0040606993957454434, 197.68755865097046), (0.8, 0.06404456217233037, 0.004101705943845489, 203.95586252212524), (1.0, 0.06397686500683773, 0.0040930392561031375, 195.0188548564911)]"
     ]
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4533d30bf5ed475f96f2f2a74617b6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = spark.createDataFrame(result_list,('percentage', 'rmse','mse','time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e814877821f84a75b004f99bba837aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   percentage      rmse       mse        time\n",
      "0         0.2  0.063829  0.004074  203.510483\n",
      "1         0.4  0.063724  0.004061  197.687559\n",
      "2         0.8  0.064045  0.004102  203.955863\n",
      "3         1.0  0.063977  0.004093  195.018855"
     ]
    }
   ],
   "source": [
    "result_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.write.csv('s3n://shelly-678-project/1-master-3-work')\n",
    "\n",
    "# \"s3://shelly-678-project/simplified_train.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Step 7:</b> Build a Deep Learning Model\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
